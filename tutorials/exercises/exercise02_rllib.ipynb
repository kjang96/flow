{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 02: Running RLlib Experiments\n",
    "\n",
    "This tutorial walks you through the process of running traffic simulations in Flow with trainable RLlib-powered agents. Autonomous agents will learn to maximize a certain reward over the rollouts, using the **RLlib** library. Simulations of this form will depict the propensity of RL agents to influence the traffic of a human fleet in order to make the whole fleet more efficient (for some given metrics). \n",
    "\n",
    "In this exercise, we simulate an initially perturbed single lane ring road, where we introduce a single autonomous vehicle. We witness that, after some training, that the autonomous vehicle learns to dissipate the formation and propagation of \"phantom jams\" which form when only human driver dynamics are involved.\n",
    "\n",
    "## 1. Components of a Simulation\n",
    "All simulations, both in the presence and absence of RL, require two components: a *scenario*, and an *environment*. Scenarios describe the features of the transportation network used in simulation. This includes the positions and properties of nodes and edges constituting the lanes and junctions, as well as properties of the vehicles, traffic lights, inflows, etc... in the network. Environments, on the other hand, initialize, reset, and advance simulations, and act as the primary interface between the reinforcement learning algorithm and the scenario. Moreover, custom environments may be used to modify the dynamical features of an scenario. Finally, in the RL case, it is in the *environment* that the state/action spaces and the reward function are defined. \n",
    "\n",
    "## 2. Setting up a Scenario\n",
    "Flow contains a plethora of pre-designed scenarios used to replicate highways, intersections, and merges in both closed and open settings. All these scenarios are located in flow/scenarios. For this exercise, which involves a single lane ring road, we will use the scenario `LoopScenario`.\n",
    "\n",
    "### 2.1 Setting up Scenario Parameters\n",
    "\n",
    "The scenario mentioned at the start of this section, as well as all other scenarios in Flow, are parameterized by the following arguments: \n",
    "* name\n",
    "* generator_class\n",
    "* vehicles\n",
    "* net_params\n",
    "* initial_config\n",
    "\n",
    "These parameters are explained in detail in exercise 1. Moreover, all parameters excluding vehicles (covered in section 2.2) do not change from the previous exercise. Accordingly, we specify them nearly as we have before, and leave further explanations of the parameters to exercise 1. In RLlib experiments, the scenario and generator types do not need to be defined; instead users should name the scenario and generator. Later on, an environment setup module will import the correct scenario and generator classes based on the provided names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ring road scenario class\n",
    "scenario_name = \"LoopScenario\"\n",
    "\n",
    "# ring road generator class\n",
    "generator_name = \"CircleGenerator\"\n",
    "\n",
    "# input parameter classes to the scenario class\n",
    "from flow.core.params import NetParams, InitialConfig\n",
    "\n",
    "# name of the scenario\n",
    "name = \"training_example\"\n",
    "\n",
    "# network-specific parameters\n",
    "from flow.scenarios.loop.loop_scenario import ADDITIONAL_NET_PARAMS\n",
    "net_params = NetParams(additional_params=ADDITIONAL_NET_PARAMS)\n",
    "\n",
    "# initial configuration to vehicles\n",
    "initial_config = InitialConfig(spacing=\"uniform\", perturbation=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Adding Trainable Autonomous Vehicles\n",
    "The `Vehicles` class stores state information on all vehicles in the network. This class is used to identify the dynamical features of a vehicle and whether it is controlled by a reinforcement learning agent. Morover, information pertaining to the observations and reward function can be collected from various `get` methods within this class.\n",
    "\n",
    "The dynamics of vehicles in the `Vehicles` class can either be depicted by sumo or by the dynamical methods located in flow/controllers. For human-driven vehicles, we use the IDM model for acceleration behavior, with exogenous gaussian acceleration noise with std 0.2 m/s2 to induce perturbations that produce stop-and-go behavior. In addition, we use the `ContinousRouter` routing controller so that the vehicles may maintain their routes closed networks.\n",
    "\n",
    "As we have done in exercise 1, human-driven vehicles are defined in the `Vehicles` class as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vehicles class\n",
    "from flow.core.vehicles import Vehicles\n",
    "\n",
    "# vehicles dynamics models\n",
    "from flow.controllers import IDMController, ContinuousRouter\n",
    "\n",
    "vehicles = Vehicles()\n",
    "vehicles.add(\"human\",\n",
    "             acceleration_controller=(IDMController, {}),\n",
    "             routing_controller=(ContinuousRouter, {}),\n",
    "             num_vehicles=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above addition to the `Vehicles` class only accounts for 21 of the 22 vehicles that are placed in the network. We now add an additional trainable autuonomous vehicle whose actions are dictated by an RL agent. This is done by specifying an `RLController` as the acceleraton controller to the vehicle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from flow.controllers import RLController"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this controller serves primarirly as a placeholder that marks the vehicle as a component of the RL agent, meaning that lane changing and routing actions can also be specified by the RL agent to this vehicle.\n",
    "\n",
    "We finally add the vehicle as follows, while again using the `ContinuousRouter` to perpetually maintain the vehicle within the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vehicles.add(veh_id=\"rl\",\n",
    "             acceleration_controller=(RLController, {}),\n",
    "             routing_controller=(ContinuousRouter, {}),\n",
    "             num_vehicles=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setting up an Environment\n",
    "\n",
    "Several environments in Flow exist to train RL agents of different forms (e.g. autonomous vehicles, traffic lights) to perform a variety of different tasks. The use of an environment allows us to view the cumulative reward simulation rollouts receive, along with to specify the state/action spaces.\n",
    "\n",
    "Envrionments in Flow are parametrized by three components:\n",
    "* env_params\n",
    "* sumo_params\n",
    "* scenario\n",
    "\n",
    "### 3.1 SumoParams\n",
    "`SumoParams` specifies simulation-specific variables. These variables include the length of any simulation step and whether to render the GUI when running the experiment. For this example, we consider a simulation step length of 0.1s and activate the GUI. \n",
    "\n",
    "**Note** For training purposes, it is highly recommanded to deactivate the GUI in order to avoid global slow down. In such case, one just needs to specify the following: `sumo_binary=\"sumo\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from flow.core.params import SumoParams\n",
    "\n",
    "sumo_params = SumoParams(sim_step=0.1, sumo_binary=\"sumo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 EnvParams\n",
    "\n",
    "`EnvParams` specifies environment and experiment-specific parameters that either affect the training process or the dynamics of various components within the scenario. For the environment `WaveAttenuationPOEnv`, these parameters are used to dictate bounds on the accelerations of the autonomous vehicles, as well as the range of ring lengths (and accordingly network densities) the agent is trained on.\n",
    "\n",
    "Finally, it is important to specify here the *horizon* of the experiment, which is the duration of one episode (during which the RL-agent acquire data). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from flow.core.params import EnvParams\n",
    "\n",
    "# Define horizon as a variable to ensure consistent use across notebook\n",
    "HORIZON=100\n",
    "\n",
    "env_params = EnvParams(\n",
    "    # length of one rollout\n",
    "    horizon=HORIZON,\n",
    "\n",
    "    additional_params={\n",
    "        # maximum acceleration of autonomous vehicles\n",
    "        \"max_accel\": 1,\n",
    "        # maximum deceleration of autonomous vehicles\n",
    "        \"max_decel\": 1,\n",
    "        # bounds on the ranges of ring road lengths the autonomous vehicle \n",
    "        # is trained on\n",
    "        \"ring_length\": [220, 270],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Initializing a Gym Environment\n",
    "\n",
    "Now, we have to specify our Gym Environment and the algorithm that our RL agents will use. To specify the environment, one has to use the environment's name (a simple string). A list of all environment names is located in `flow/envs/__init__.py`. The names of available environments can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Env', 'AccelEnv', 'LaneChangeAccelEnv', 'LaneChangeAccelPOEnv', 'GreenWaveTestEnv', 'GreenWaveEnv', 'WaveAttenuationMergePOEnv', 'TwoLoopsMergeEnv', 'BottleneckEnv', 'BottleNeckAccelEnv', 'WaveAttenuationEnv', 'WaveAttenuationPOEnv']\n"
     ]
    }
   ],
   "source": [
    "import flow.envs as flowenvs\n",
    "\n",
    "print(flowenvs.__all__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the environment \"WaveAttenuationPOEnv\", which is used to train autonomous vehicles to attenuate the formation and propagation of waves in a partially observable variable density ring road. To create the Gym Environment, the only necessary parameters are the environment name plus the previously defined variables. These are defined as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env_name = \"WaveAttenuationPOEnv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Setting up Flow Parameters\n",
    "\n",
    "RLlib and rllab experiments both generate a `params.json` file for each experiment run. For RLlib experiments, the parameters defining the Flow scenario and environment must be stored as well. As such, in this section we define the dictionary `flow_params`, which contains the variables required by the utility function `make_create_env`. `make_create_env` is a higher-order function which returns a function `create_env` that initializes a Gym environment corresponding to the Flow scenario specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating flow_params. Make sure the dictionary keys are as specified. \n",
    "flow_params = dict(\n",
    "    exp_tag=name,  # experiment name\n",
    "    env_name=env_name,  # environment name as specified earlier\n",
    "    scenario=scenario_name,  # scenario name as specified earlier\n",
    "    generator=generator_name,  # generator name as specified earlier\n",
    "    sumo=sumo_params,  # params objects as created earlier\n",
    "    env=env_params,\n",
    "    net=net_params,\n",
    "    veh=vehicles,  # vehicles object\n",
    "    initial=initial_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Running RL experiments in Ray\n",
    "\n",
    "### 4.1 Import \n",
    "\n",
    "First, we must import modules required to run experiments in Ray. The `json` package is required to store the Flow experiment parameters in the `params.json` file, as is `FlowParamsEncoder`. Ray-related imports are required: the PPO algorithm agent, `ray.tune`'s experiment runner, and environment helper methods `register_env` and `make_create_env`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import ray\n",
    "import ray.rllib.ppo as ppo\n",
    "from ray.tune import run_experiments\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "from flow.utils.rllib import make_create_env, FlowParamsEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Initializing Ray\n",
    "Here, we initialize Ray and experiment-based constant variables specifying parallelism in the experiment as well as experiment batch size in terms of number of rollouts. `redirect_output` sends stdout and stderr for non-worker processes to files if True. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process STDOUT and STDERR is being redirected to /tmp/raylogs/.\n",
      "Waiting for redis server at 127.0.0.1:54414 to respond...\n",
      "Waiting for redis server at 127.0.0.1:57842 to respond...\n",
      "Starting local scheduler with the following resources: {'CPU': 2, 'GPU': 0}.\n",
      "\n",
      "======================================================================\n",
      "View the web UI at http://localhost:8889/notebooks/ray_ui19106.ipynb?token=526433116f1827b467871e4da82460abf0abf63773da3229\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'local_scheduler_socket_names': ['/tmp/scheduler39671083'],\n",
       " 'node_ip_address': '10.142.38.11',\n",
       " 'object_store_addresses': [ObjectStoreAddress(name='/tmp/plasma_store42183956', manager_name='/tmp/plasma_manager40325941', manager_port=39554)],\n",
       " 'raylet_socket_names': [],\n",
       " 'redis_address': '10.142.38.11:54414',\n",
       " 'webui_url': 'http://localhost:8889/notebooks/ray_ui19106.ipynb?token=526433116f1827b467871e4da82460abf0abf63773da3229'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of parallel workers\n",
    "PARALLEL_ROLLOUTS = 2\n",
    "# number of rollouts per training iteration\n",
    "N_ROLLOUTS = 20\n",
    "\n",
    "ray.init(num_cpus=PARALLEL_ROLLOUTS, redirect_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Configuration and Setup\n",
    "Here, we copy and modify the default configuration for the [PPO algorithm](https://arxiv.org/abs/1707.06347). The agent has the number of parallel workers specified, a batch size corresponding to `N_ROLLOUTS` rollouts (each of which has length `HORIZON` steps), a discount rate $\\gamma$ of 0.999, two hidden layers of size 16, uses Generalized Advantage Estimation, $\\lambda$ of 0.97, and other parameters as set below.\n",
    "\n",
    "Once `config` contains the desired parameters, a JSON string corresponding to the `flow_params` specified in section 3 is generated. The `FlowParamsEncoder` maps objects to string representations so that the experiment can be reproduced later. That string representation is stored within the `env_config` section of the `config` dictionary. Later, `config` is written out to the file `params.json`. \n",
    "\n",
    "Next, we call `make_create_env` and pass in the `flow_params` to return a function we can use to register our Flow environment with Gym. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute '__name__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-df869b6a304a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# save the flow params for replay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m flow_json = json.dumps(flow_params, cls=FlowParamsEncoder, sort_keys=True,\n\u001b[0;32m---> 15\u001b[0;31m                        indent=4)  # generating a string version of flow_params\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'env_config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'flow_params'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflow_json\u001b[0m  \u001b[0;31m# adding the flow_params to config dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/flow/lib/python3.5/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mcheck_circular\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_circular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_nan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mseparators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseparators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         **kw).encode(obj)\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/flow/lib/python3.5/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/flow/lib/python3.5/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/flow/lib/python3.5/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    401\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/flow/lib/python3.5/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    434\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Circular reference detected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m                 \u001b[0mmarkers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmarkerid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m             \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Development/research/rllab-multiagent/learning-traffic/flow/utils/rllib.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mres_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                     \u001b[0mres_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"acceleration_controller\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                         (res_i[\"acceleration_controller\"][0].__name__,\n\u001b[0m\u001b[1;32m    124\u001b[0m                          res_i[\"acceleration_controller\"][1])\n\u001b[1;32m    125\u001b[0m                     \u001b[0mres_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lane_change_controller\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute '__name__'"
     ]
    }
   ],
   "source": [
    "config=ppo.DEFAULT_CONFIG.copy()\n",
    "config[\"num_workers\"] = PARALLEL_ROLLOUTS  # number of parallel workers\n",
    "config[\"timesteps_per_batch\"] = HORIZON * N_ROLLOUTS  # batch size\n",
    "config[\"gamma\"] = 0.999  # discount rate\n",
    "config[\"model\"].update({\"fcnet_hiddens\": [16, 16]})  # size of hidden layers in network\n",
    "config[\"use_gae\"] = True  # using generalized advantage estimation\n",
    "config[\"lambda\"] = 0.97  \n",
    "config[\"sgd_batchsize\"] = min(16 * 1024, config[\"timesteps_per_batch\"])  # stochastic gradient descent\n",
    "config[\"kl_target\"] = 0.02  # target KL divergence\n",
    "config[\"num_sgd_iter\"] = 10  # number of SGD iterations\n",
    "config[\"horizon\"] = HORIZON  # rollout horizon\n",
    "\n",
    "# save the flow params for replay\n",
    "flow_json = json.dumps(flow_params, cls=FlowParamsEncoder, sort_keys=True,\n",
    "                       indent=4)  # generating a string version of flow_params\n",
    "config['env_config']['flow_params'] = flow_json  # adding the flow_params to config dict\n",
    "\n",
    "# Call the utility function make_create_env to be able to \n",
    "# register the Flow env for this experiment\n",
    "create_env, env_name = make_create_env(params=flow_params, version=0)\n",
    "\n",
    "# Register as rllib env with Gym\n",
    "register_env(env_name, create_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Running Experiments\n",
    "\n",
    "Here, we use the `run_experiments` function from `ray.tune`. The function takes a dictionary with one key, a name corresponding to the experiment, and one value, itself a dictionary containing parameters for training. Here, the name `ring_stabilize` would be the folder within your `ray_results/` directory containing results for each training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Result logdir: /Users/nishant/ray_results/ring_stabilize\n",
      "PENDING trials:\n",
      " - PPO_WaveAttenuationPOEnv-v0_0:\tPENDING\n",
      " - PPO_WaveAttenuationPOEnv-v0_1:\tPENDING\n",
      " - PPO_WaveAttenuationPOEnv-v0_2:\tPENDING\n",
      "\n",
      "Created LogSyncer for /Users/nishant/ray_results/ring_stabilize/PPO_WaveAttenuationPOEnv-v0_0_2018-06-05_15-17-10cza8jzll -> \n",
      "WARNING: Serializing objects of type <class 'ray.tune.registry._Registry'> by expanding them as dictionaries of their fields. This behavior may be incorrect in some cases.\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 2/2 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/nishant/ray_results/ring_stabilize\n",
      "PENDING trials:\n",
      " - PPO_WaveAttenuationPOEnv-v0_1:\tPENDING\n",
      " - PPO_WaveAttenuationPOEnv-v0_2:\tPENDING\n",
      "RUNNING trials:\n",
      " - PPO_WaveAttenuationPOEnv-v0_0:\tRUNNING\n",
      "\n",
      "Remote function \u001b[31m__init__\u001b[39m failed with:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/worker.py\", line 862, in _process_task\n",
      "    *arguments)\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/actor.py\", line 245, in actor_method_executor\n",
      "    method_returns = method(actor, *args)\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/rllib/agent.py\", line 84, in __init__\n",
      "    Trainable.__init__(self, config, registry, logger_creator)\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/tune/trainable.py\", line 90, in __init__\n",
      "    self._setup()\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/rllib/agent.py\", line 91, in _setup\n",
      "    self.env_creator = self.registry.get(ENV_CREATOR, env)\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/tune/registry.py\", line 97, in get\n",
      "    return _from_pinnable(ray.get(value))\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/worker.py\", line 2474, in get\n",
      "    value = worker.get_object([object_ids])[0]\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/worker.py\", line 454, in get_object\n",
      "    final_results = self.retrieve_and_deserialize(plain_object_ids, 0)\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/worker.py\", line 389, in retrieve_and_deserialize\n",
      "    timeout, self.serialization_context)\n",
      "  File \"plasma.pyx\", line 429, in pyarrow.plasma.PlasmaClient.get\n",
      "  File \"serialization.pxi\", line 441, in pyarrow.lib.deserialize\n",
      "  File \"serialization.pxi\", line 404, in pyarrow.lib.deserialize_from\n",
      "  File \"serialization.pxi\", line 257, in pyarrow.lib.SerializedPyObject.deserialize\n",
      "  File \"serialization.pxi\", line 165, in pyarrow.lib.SerializationContext._deserialize_callback\n",
      "  File \"/Users/nishant/Development/research/rllab-multiagent/learning-traffic/flow/core/vehicles.py\", line 10, in <module>\n",
      "    import traci.constants as tc\n",
      "  File \"/Users/nishant/Development/research/sumo/tools/traci/__init__.py\", line 31, in <module>\n",
      "    import sumolib  # noqa\n",
      "  File \"/Users/nishant/Development/research/sumo/tools/sumolib/__init__.py\", line 30, in <module>\n",
      "    from . import visualization\n",
      "  File \"/Users/nishant/Development/research/sumo/tools/sumolib/visualization/__init__.py\", line 21, in <module>\n",
      "    from . import helpers\n",
      "  File \"/Users/nishant/Development/research/sumo/tools/sumolib/visualization/helpers.py\", line 27, in <module>\n",
      "    from pylab import *\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/pylab.py\", line 1, in <module>\n",
      "    from matplotlib.pylab import *\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/matplotlib/pylab.py\", line 257, in <module>\n",
      "    from matplotlib import cbook, mlab, pyplot as plt\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/matplotlib/pyplot.py\", line 115, in <module>\n",
      "    _backend_mod, new_figure_manager, draw_if_interactive, _show = pylab_setup()\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/matplotlib/backends/__init__.py\", line 32, in pylab_setup\n",
      "    globals(),locals(),[backend_name],0)\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/ipykernel/__init__.py\", line 2, in <module>\n",
      "    from .connect import *\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/ipykernel/connect.py\", line 18, in <module>\n",
      "    import jupyter_client\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/jupyter_client/__init__.py\", line 7, in <module>\n",
      "    from .manager import KernelManager, run_kernel\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/jupyter_client/manager.py\", line 32, in <module>\n",
      "    from .session import Session\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/jupyter_client/session.py\", line 56, in <module>\n",
      "    from zmq.eventloop.ioloop import IOLoop\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/zmq/eventloop/__init__.py\", line 3, in <module>\n",
      "    from zmq.eventloop.ioloop import IOLoop\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 35, in <module>\n",
      "    from tornado.ioloop import PollIOLoop, PeriodicCallback\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/tornado/ioloop.py\", line 47, in <module>\n",
      "    from tornado.concurrent import TracebackFuture, is_future\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/tornado/concurrent.py\", line 37, in <module>\n",
      "    from concurrent import futures\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/concurrent/futures/__init__.py\", line 8, in <module>\n",
      "    from concurrent.futures._base import (FIRST_COMPLETED,\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/concurrent/futures/_base.py\", line 381\n",
      "    raise exception_type, self._exception, self._traceback\n",
      "                        ^\n",
      "SyntaxError: invalid syntax\n",
      "\n",
      "\n",
      "  You can inspect errors by running\n",
      "\n",
      "      ray.error_info()\n",
      "\n",
      "  If this driver is hanging, start a new one with\n",
      "\n",
      "      ray.init(redis_address=\"10.142.38.11:54414\")\n",
      "  \n",
      "Remote function \u001b[31mtrain\u001b[39m failed with:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/worker.py\", line 862, in _process_task\n",
      "    *arguments)\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/actor.py\", line 245, in actor_method_executor\n",
      "    method_returns = method(actor, *args)\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/tune/trainable.py\", line 123, in train\n",
      "    \"Trainable initialization failed, see previous errors\")\n",
      "ValueError: Trainable initialization failed, see previous errors\n",
      "\n",
      "\n",
      "  You can inspect errors by running\n",
      "\n",
      "      ray.error_info()\n",
      "\n",
      "  If this driver is hanging, start a new one with\n",
      "\n",
      "      ray.init(redis_address=\"10.142.38.11:54414\")\n",
      "  \n",
      "Error processing event: Traceback (most recent call last):\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/tune/trial_runner.py\", line 255, in _process_events\n",
      "    result = ray.get(result_id)\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/worker.py\", line 2479, in get\n",
      "    raise RayGetError(object_ids, value)\n",
      "ray.worker.RayGetError: Could not get objectid ObjectID(f31c13dd3f070d16be6e7f989f7f1eaac8f23db1). It was created by remote function \u001b[31mtrain\u001b[39m which failed with:\n",
      "\n",
      "Remote function \u001b[31mtrain\u001b[39m failed with:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/worker.py\", line 862, in _process_task\n",
      "    *arguments)\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/actor.py\", line 245, in actor_method_executor\n",
      "    method_returns = method(actor, *args)\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/tune/trainable.py\", line 123, in train\n",
      "    \"Trainable initialization failed, see previous errors\")\n",
      "ValueError: Trainable initialization failed, see previous errors\n",
      "\n",
      "\n",
      "Worker ip unknown, skipping log sync for /Users/nishant/ray_results/ring_stabilize/PPO_WaveAttenuationPOEnv-v0_0_2018-06-05_15-17-10cza8jzll\n",
      "Created LogSyncer for /Users/nishant/ray_results/ring_stabilize/PPO_WaveAttenuationPOEnv-v0_1_2018-06-05_15-17-15bo4gyf96 -> \n",
      "Remote function \u001b[31m__init__\u001b[39m failed with:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/worker.py\", line 862, in _process_task\n",
      "    *arguments)\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/actor.py\", line 245, in actor_method_executor\n",
      "    method_returns = method(actor, *args)\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/rllib/agent.py\", line 84, in __init__\n",
      "    Trainable.__init__(self, config, registry, logger_creator)\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/tune/trainable.py\", line 90, in __init__\n",
      "    self._setup()\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/rllib/agent.py\", line 91, in _setup\n",
      "    self.env_creator = self.registry.get(ENV_CREATOR, env)\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/tune/registry.py\", line 97, in get\n",
      "    return _from_pinnable(ray.get(value))\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/worker.py\", line 2474, in get\n",
      "    value = worker.get_object([object_ids])[0]\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/worker.py\", line 454, in get_object\n",
      "    final_results = self.retrieve_and_deserialize(plain_object_ids, 0)\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/worker.py\", line 389, in retrieve_and_deserialize\n",
      "    timeout, self.serialization_context)\n",
      "  File \"plasma.pyx\", line 429, in pyarrow.plasma.PlasmaClient.get\n",
      "  File \"serialization.pxi\", line 441, in pyarrow.lib.deserialize\n",
      "  File \"serialization.pxi\", line 404, in pyarrow.lib.deserialize_from\n",
      "  File \"serialization.pxi\", line 257, in pyarrow.lib.SerializedPyObject.deserialize\n",
      "  File \"serialization.pxi\", line 165, in pyarrow.lib.SerializationContext._deserialize_callback\n",
      "  File \"/Users/nishant/Development/research/rllab-multiagent/learning-traffic/flow/core/vehicles.py\", line 10, in <module>\n",
      "    import traci.constants as tc\n",
      "  File \"/Users/nishant/Development/research/sumo/tools/traci/__init__.py\", line 31, in <module>\n",
      "    import sumolib  # noqa\n",
      "  File \"/Users/nishant/Development/research/sumo/tools/sumolib/__init__.py\", line 30, in <module>\n",
      "    from . import visualization\n",
      "  File \"/Users/nishant/Development/research/sumo/tools/sumolib/visualization/__init__.py\", line 21, in <module>\n",
      "    from . import helpers\n",
      "  File \"/Users/nishant/Development/research/sumo/tools/sumolib/visualization/helpers.py\", line 27, in <module>\n",
      "    from pylab import *\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/pylab.py\", line 1, in <module>\n",
      "    from matplotlib.pylab import *\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/matplotlib/pylab.py\", line 257, in <module>\n",
      "    from matplotlib import cbook, mlab, pyplot as plt\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/matplotlib/pyplot.py\", line 115, in <module>\n",
      "    _backend_mod, new_figure_manager, draw_if_interactive, _show = pylab_setup()\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/matplotlib/backends/__init__.py\", line 32, in pylab_setup\n",
      "    globals(),locals(),[backend_name],0)\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/ipykernel/__init__.py\", line 2, in <module>\n",
      "    from .connect import *\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/ipykernel/connect.py\", line 18, in <module>\n",
      "    import jupyter_client\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/jupyter_client/__init__.py\", line 7, in <module>\n",
      "    from .manager import KernelManager, run_kernel\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/jupyter_client/manager.py\", line 32, in <module>\n",
      "    from .session import Session\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/jupyter_client/session.py\", line 56, in <module>\n",
      "    from zmq.eventloop.ioloop import IOLoop\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/zmq/eventloop/__init__.py\", line 3, in <module>\n",
      "    from zmq.eventloop.ioloop import IOLoop\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 35, in <module>\n",
      "    from tornado.ioloop import PollIOLoop, PeriodicCallback\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/tornado/ioloop.py\", line 47, in <module>\n",
      "    from tornado.concurrent import TracebackFuture, is_future\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/tornado/concurrent.py\", line 37, in <module>\n",
      "    from concurrent import futures\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/concurrent/futures/__init__.py\", line 8, in <module>\n",
      "    from concurrent.futures._base import (FIRST_COMPLETED,\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/concurrent/futures/_base.py\", line 381\n",
      "    raise exception_type, self._exception, self._traceback\n",
      "                        ^\n",
      "SyntaxError: invalid syntax\n",
      "\n",
      "\n",
      "  You can inspect errors by running\n",
      "\n",
      "      ray.error_info()\n",
      "\n",
      "  If this driver is hanging, start a new one with\n",
      "\n",
      "      ray.init(redis_address=\"10.142.38.11:54414\")\n",
      "  \n",
      "Remote function \u001b[31mtrain\u001b[39m failed with:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/worker.py\", line 862, in _process_task\n",
      "    *arguments)\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/actor.py\", line 245, in actor_method_executor\n",
      "    method_returns = method(actor, *args)\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/tune/trainable.py\", line 123, in train\n",
      "    \"Trainable initialization failed, see previous errors\")\n",
      "ValueError: Trainable initialization failed, see previous errors\n",
      "\n",
      "Error processing event:\n",
      "  You can inspect errors by running\n",
      "\n",
      "      ray.error_info()\n",
      "\n",
      "  If this driver is hanging, start a new one with\n",
      "\n",
      "      ray.init(redis_address=\"10.142.38.11:54414\")\n",
      "   \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/tune/trial_runner.py\", line 255, in _process_events\n",
      "    result = ray.get(result_id)\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/worker.py\", line 2479, in get\n",
      "    raise RayGetError(object_ids, value)\n",
      "ray.worker.RayGetError: Could not get objectid ObjectID(0e8192e9e5d720bf3438b2fdad4e7192a24ee9de). It was created by remote function \u001b[31mtrain\u001b[39m which failed with:\n",
      "\n",
      "Remote function \u001b[31mtrain\u001b[39m failed with:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/worker.py\", line 862, in _process_task\n",
      "    *arguments)\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/actor.py\", line 245, in actor_method_executor\n",
      "    method_returns = method(actor, *args)\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/tune/trainable.py\", line 123, in train\n",
      "    \"Trainable initialization failed, see previous errors\")\n",
      "ValueError: Trainable initialization failed, see previous errors\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker ip unknown, skipping log sync for /Users/nishant/ray_results/ring_stabilize/PPO_WaveAttenuationPOEnv-v0_1_2018-06-05_15-17-15bo4gyf96\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/2 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/nishant/ray_results/ring_stabilize\n",
      "ERROR trials:\n",
      " - PPO_WaveAttenuationPOEnv-v0_0:\tERROR, 1 failures: /Users/nishant/ray_results/ring_stabilize/PPO_WaveAttenuationPOEnv-v0_0_2018-06-05_15-17-10cza8jzll/error_2018-06-05_15-17-15.txt\n",
      " - PPO_WaveAttenuationPOEnv-v0_1:\tERROR, 1 failures: /Users/nishant/ray_results/ring_stabilize/PPO_WaveAttenuationPOEnv-v0_1_2018-06-05_15-17-15bo4gyf96/error_2018-06-05_15-17-16.txt\n",
      "PENDING trials:\n",
      " - PPO_WaveAttenuationPOEnv-v0_2:\tPENDING\n",
      "\n",
      "Created LogSyncer for /Users/nishant/ray_results/ring_stabilize/PPO_WaveAttenuationPOEnv-v0_2_2018-06-05_15-17-17m1voqjq6 -> \n",
      "Remote function \u001b[31m__init__\u001b[39m failed with:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/worker.py\", line 862, in _process_task\n",
      "    *arguments)\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/actor.py\", line 245, in actor_method_executor\n",
      "    method_returns = method(actor, *args)\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/rllib/agent.py\", line 84, in __init__\n",
      "    Trainable.__init__(self, config, registry, logger_creator)\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/tune/trainable.py\", line 90, in __init__\n",
      "    self._setup()\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/rllib/agent.py\", line 91, in _setup\n",
      "    self.env_creator = self.registry.get(ENV_CREATOR, env)\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/tune/registry.py\", line 97, in get\n",
      "    return _from_pinnable(ray.get(value))\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/worker.py\", line 2474, in get\n",
      "    value = worker.get_object([object_ids])[0]\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/worker.py\", line 454, in get_object\n",
      "    final_results = self.retrieve_and_deserialize(plain_object_ids, 0)\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/worker.py\", line 389, in retrieve_and_deserialize\n",
      "    timeout, self.serialization_context)\n",
      "  File \"plasma.pyx\", line 429, in pyarrow.plasma.PlasmaClient.get\n",
      "  File \"serialization.pxi\", line 441, in pyarrow.lib.deserialize\n",
      "  File \"serialization.pxi\", line 404, in pyarrow.lib.deserialize_from\n",
      "  File \"serialization.pxi\", line 257, in pyarrow.lib.SerializedPyObject.deserialize\n",
      "  File \"serialization.pxi\", line 165, in pyarrow.lib.SerializationContext._deserialize_callback\n",
      "  File \"/Users/nishant/Development/research/rllab-multiagent/learning-traffic/flow/core/vehicles.py\", line 10, in <module>\n",
      "    import traci.constants as tc\n",
      "  File \"/Users/nishant/Development/research/sumo/tools/traci/__init__.py\", line 31, in <module>\n",
      "    import sumolib  # noqa\n",
      "  File \"/Users/nishant/Development/research/sumo/tools/sumolib/__init__.py\", line 30, in <module>\n",
      "    from . import visualization\n",
      "  File \"/Users/nishant/Development/research/sumo/tools/sumolib/visualization/__init__.py\", line 21, in <module>\n",
      "    from . import helpers\n",
      "  File \"/Users/nishant/Development/research/sumo/tools/sumolib/visualization/helpers.py\", line 27, in <module>\n",
      "    from pylab import *\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/pylab.py\", line 1, in <module>\n",
      "    from matplotlib.pylab import *\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/matplotlib/pylab.py\", line 257, in <module>\n",
      "    from matplotlib import cbook, mlab, pyplot as plt\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/matplotlib/pyplot.py\", line 115, in <module>\n",
      "    _backend_mod, new_figure_manager, draw_if_interactive, _show = pylab_setup()\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/matplotlib/backends/__init__.py\", line 32, in pylab_setup\n",
      "    globals(),locals(),[backend_name],0)\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/ipykernel/__init__.py\", line 2, in <module>\n",
      "    from .connect import *\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/ipykernel/connect.py\", line 18, in <module>\n",
      "    import jupyter_client\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/jupyter_client/__init__.py\", line 7, in <module>\n",
      "    from .manager import KernelManager, run_kernel\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/jupyter_client/manager.py\", line 32, in <module>\n",
      "    from .session import Session\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/jupyter_client/session.py\", line 56, in <module>\n",
      "    from zmq.eventloop.ioloop import IOLoop\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/zmq/eventloop/__init__.py\", line 3, in <module>\n",
      "    from zmq.eventloop.ioloop import IOLoop\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 35, in <module>\n",
      "    from tornado.ioloop import PollIOLoop, PeriodicCallback\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/tornado/ioloop.py\", line 47, in <module>\n",
      "    from tornado.concurrent import TracebackFuture, is_future\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/tornado/concurrent.py\", line 37, in <module>\n",
      "    from concurrent import futures\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/concurrent/futures/__init__.py\", line 8, in <module>\n",
      "    from concurrent.futures._base import (FIRST_COMPLETED,\n",
      "  File \"/Users/nishant/anaconda3/envs/flow/lib/python3.5/site-packages/concurrent/futures/_base.py\", line 381\n",
      "    raise exception_type, self._exception, self._traceback\n",
      "                        ^\n",
      "SyntaxError: invalid syntax\n",
      "\n",
      "\n",
      "  You can inspect errors by running\n",
      "\n",
      "      ray.error_info()\n",
      "\n",
      "  If this driver is hanging, start a new one with\n",
      "\n",
      "      ray.init(redis_address=\"10.142.38.11:54414\")\n",
      "  \n",
      "Error processing event: Remote function \u001b[31mtrain\u001b[39m failed with:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/worker.py\", line 862, in _process_task\n",
      "    *arguments)\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/actor.py\", line 245, in actor_method_executor\n",
      "    method_returns = method(actor, *args)\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/tune/trainable.py\", line 123, in train\n",
      "    \"Trainable initialization failed, see previous errors\")\n",
      "ValueError: Trainable initialization failed, see previous errors\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/tune/trial_runner.py\", line 255, in _process_events\n",
      "    result = ray.get(result_id)\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/worker.py\", line 2479, in get\n",
      "    raise RayGetError(object_ids, value)\n",
      "ray.worker.RayGetError: Could not get objectid ObjectID(ff0bcf4b3b95723dbc19ef116cd650897982ce0b). It was created by remote function \u001b[31mtrain\u001b[39m which failed with:\n",
      "\n",
      "Remote function \u001b[31mtrain\u001b[39m failed with:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/worker.py\", line 862, in _process_task\n",
      "    *arguments)\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/actor.py\", line 245, in actor_method_executor\n",
      "    method_returns = method(actor, *args)\n",
      "  File \"/Users/nishant/Development/research/ray/python/ray/tune/trainable.py\", line 123, in train\n",
      "    \"Trainable initialization failed, see previous errors\")\n",
      "ValueError: Trainable initialization failed, see previous errors\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  You can inspect errors by running\n",
      "\n",
      "      ray.error_info()\n",
      "\n",
      "  If this driver is hanging, start a new one with\n",
      "\n",
      "      ray.init(redis_address=\"10.142.38.11:54414\")\n",
      "  \n",
      "Worker ip unknown, skipping log sync for /Users/nishant/ray_results/ring_stabilize/PPO_WaveAttenuationPOEnv-v0_2_2018-06-05_15-17-17m1voqjq6\n",
      "== Status ==\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/2 CPUs, 0/0 GPUs\n",
      "Result logdir: /Users/nishant/ray_results/ring_stabilize\n",
      "ERROR trials:\n",
      " - PPO_WaveAttenuationPOEnv-v0_0:\tERROR, 1 failures: /Users/nishant/ray_results/ring_stabilize/PPO_WaveAttenuationPOEnv-v0_0_2018-06-05_15-17-10cza8jzll/error_2018-06-05_15-17-15.txt\n",
      " - PPO_WaveAttenuationPOEnv-v0_1:\tERROR, 1 failures: /Users/nishant/ray_results/ring_stabilize/PPO_WaveAttenuationPOEnv-v0_1_2018-06-05_15-17-15bo4gyf96/error_2018-06-05_15-17-16.txt\n",
      " - PPO_WaveAttenuationPOEnv-v0_2:\tERROR, 1 failures: /Users/nishant/ray_results/ring_stabilize/PPO_WaveAttenuationPOEnv-v0_2_2018-06-05_15-17-17m1voqjq6/error_2018-06-05_15-17-21.txt\n",
      "\n"
     ]
    },
    {
     "ename": "TuneError",
     "evalue": "('Trial did not complete', PPO_WaveAttenuationPOEnv-v0_0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-2d5c597cfc4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;34m\"gpu\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0;34m\"extra_cpu\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPARALLEL_ROLLOUTS\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         },\n\u001b[1;32m     19\u001b[0m     },\n",
      "\u001b[0;32m~/Development/research/ray/python/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun_experiments\u001b[0;34m(experiments, scheduler, with_server, server_port, verbose, queue_trials)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# TODO(rliaw): What about errored?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mTrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTERMINATED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trial did not complete\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mwait_for_log_sync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTuneError\u001b[0m: ('Trial did not complete', PPO_WaveAttenuationPOEnv-v0_0)"
     ]
    }
   ],
   "source": [
    "trials = run_experiments({\n",
    "    \"ring_stabilize\": {\n",
    "        \"run\": \"PPO\",  # RL algorithm to run\n",
    "        \"env\": env_name,  # environment name generated earlier\n",
    "        \"config\": {  # configuration params (must match \"run\" value)\n",
    "            **config\n",
    "        },\n",
    "        \"checkpoint_freq\": 20,  # number of iterations between checkpoints\n",
    "        \"max_failures\": 999,\n",
    "        \"stop\": {  # stopping conditions\n",
    "            \"training_iteration\": 200,  # number of iterations to stop after\n",
    "        },\n",
    "        \"repeat\": 3,  # number of times to repeat training\n",
    "        \"trial_resources\": {\n",
    "            \"cpu\": 1,\n",
    "            \"gpu\": 0,\n",
    "            \"extra_cpu\": PARALLEL_ROLLOUTS - 1,\n",
    "        },\n",
    "    },\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
